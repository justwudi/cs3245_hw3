1) To support phrasal queries, the dictionary used cannot simply map a single
term to a postings list. We will need at least 2 terms.

For example, we could use biword for our dictionary. After tokenizing and 
stemming, instead of appending the document to each terms' postings list, we 
will build our dictionary with every 2 consecutive terms and append the 
document to each one of them. We also need to store the position of the 2 terms
along with the document so that we can verify that it is part of the phrase
when querying.

Document: the quick brown fox jumps over the lazy dog
Tokenize: ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']
Stem: ['the', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazi', 'dog']

Dictionary:
{
    ['', 'the']:        [(document, 0)],
    ['the', 'quick']:   [(document, 1)],
    ['quick', 'brown']: [(document, 2)],
    ['brown', 'fox']:   [(document, 3)],
    ['fox', 'jumps']:   [(document, 4)],
    ['jumps', 'over']:  [(document, 5)],
    ['over', 'the']:    [(document, 6)],
    ['the', 'lazy']:    [(document, 7)],
    ['lazy', 'dog']:    [(document, 8)],
    ['dog', '']:        [(document, 9)]
}

The queries will have to be by 2 terms as well, so the query will need to be
transformed to a sequence of [2 terms].

We'll assume that we want to match the exact phrase and not partial phrase.

We need to keep track of the positions of each query item, querying for the 
first item is a trivial operation. For the second query item, we will have to 
intersect the results by not only the same document, but the positions must 
also be 1 position apart. This will ensure that we can match the phrase and not
two separate [2 terms] that are not connected together.


2) The score is determine by the term-weight, query-term-weight and idf. 

For the term weight, if we have long documents, it is likely that each 
individual term weight will be smaller as compare to a short documents, since 
the document length that is use to normalize the weight will be much larger 
than a short document.

For query-term-weight, a longer query term will also decrease the individual 
weight of each query term.

Lastly for idf, this is a constant value regardless of whether there is long 
document or short document or queries, thus it will be similar for both long 
and short cases.

With these factor, a long document with a long query will produce a set of 
results that have very similar score to each other, thus making it harder to 
differentiate the best result from each other. Whereas for short query and 
short document, the result produce will like be more accurate.


3) Field parametric depends on the consistency of the fields among the 
documents in order to be useful. Given that Reuters collection do not have a 
uniform quality for its meta data, it is unlikely that they have consistent 
field parametric for each document. Thus, parametric indices will not be useful 
for practical search in the Reuters collection.

Since each Reuter documents actually contains a minimun of titles and its 
content zone. Making use of this two information will certainly be able to 
provide more context for the search engine than those which is not using zone 
at all. Thus, zone would be useful for practical search in Reuters collection.